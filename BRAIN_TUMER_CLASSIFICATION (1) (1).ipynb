{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixKxickSKYx7"
   },
   "source": [
    "# BRAIN TUMOR CLASSIFICATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJtUW3x5tYAQ",
    "outputId": "f1be1d6b-6782-4be3-eee9-ebbb151f26f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/Data.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of /content/Data.zip or\n",
      "        /content/Data.zip.zip, and cannot find /content/Data.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "!unzip \"/content/Data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g70ada_3pO6z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Activation,MaxPooling2D,Conv2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogv8wsfyrR3d"
   },
   "outputs": [],
   "source": [
    "train_path=\"/content/BRAIN_TUMER_CLASS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvwJqEsWXadB"
   },
   "outputs": [],
   "source": [
    "train_datagen= ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.1  # Set the validation split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBa2-rc8Xm9p"
   },
   "outputs": [],
   "source": [
    "test_datagen= ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True  # Set the validation split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yL23e1mqsRd7",
    "outputId": "46d72286-699b-4c01-a444-a06becd2f9ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1181 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate training and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(256,256),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb8QkhyYsfTI",
    "outputId": "a2d791d0-ab61-4cc2-b999-73a7e296a80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(250,250),\n",
    "    batch_size=32,\n",
    "\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKZwfrkhUhVy"
   },
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(250,250,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJJdoohas0Oo"
   },
   "outputs": [],
   "source": [
    " #Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdmtRRLIs1Jx",
    "outputId": "64246396-0117-4112-e18a-9b2a34d82510"
   },
   "outputs": [],
   "source": [
    "batch_size=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqq0agbQY1vo",
    "outputId": "8d509a80-4ebc-4766-eb60-1cbcbfe2e74b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 19s 522ms/step - loss: 0.4317 - accuracy: 0.8364 - val_loss: 0.7731 - val_accuracy: 0.7344\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 19s 527ms/step - loss: 0.3813 - accuracy: 0.8564 - val_loss: 0.6948 - val_accuracy: 0.7422\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 19s 527ms/step - loss: 0.3830 - accuracy: 0.8616 - val_loss: 0.7661 - val_accuracy: 0.7891\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 19s 514ms/step - loss: 0.3348 - accuracy: 0.8695 - val_loss: 0.6668 - val_accuracy: 0.7656\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 19s 529ms/step - loss: 0.3268 - accuracy: 0.8755 - val_loss: 0.8787 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 20s 543ms/step - loss: 0.3018 - accuracy: 0.8947 - val_loss: 0.5932 - val_accuracy: 0.8125\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 19s 527ms/step - loss: 0.2907 - accuracy: 0.8825 - val_loss: 0.8296 - val_accuracy: 0.7031\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 20s 551ms/step - loss: 0.2289 - accuracy: 0.9138 - val_loss: 0.7688 - val_accuracy: 0.7656\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 19s 520ms/step - loss: 0.2433 - accuracy: 0.9034 - val_loss: 0.9508 - val_accuracy: 0.7422\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 22s 619ms/step - loss: 0.2806 - accuracy: 0.8851 - val_loss: 0.9652 - val_accuracy: 0.7656\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 19s 531ms/step - loss: 0.2525 - accuracy: 0.8999 - val_loss: 0.9322 - val_accuracy: 0.7188\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 20s 566ms/step - loss: 0.2141 - accuracy: 0.9164 - val_loss: 0.8519 - val_accuracy: 0.7656\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 19s 529ms/step - loss: 0.1754 - accuracy: 0.9401 - val_loss: 0.9547 - val_accuracy: 0.8203\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 20s 559ms/step - loss: 0.1658 - accuracy: 0.9391 - val_loss: 0.9000 - val_accuracy: 0.8125\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 18s 513ms/step - loss: 0.1862 - accuracy: 0.9391 - val_loss: 0.9191 - val_accuracy: 0.7656\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 19s 514ms/step - loss: 0.1413 - accuracy: 0.9547 - val_loss: 0.7829 - val_accuracy: 0.8047\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 20s 550ms/step - loss: 0.1319 - accuracy: 0.9582 - val_loss: 0.8254 - val_accuracy: 0.7812\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 19s 529ms/step - loss: 0.1129 - accuracy: 0.9582 - val_loss: 0.8133 - val_accuracy: 0.7969\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 21s 592ms/step - loss: 0.1329 - accuracy: 0.9513 - val_loss: 0.7189 - val_accuracy: 0.8359\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 20s 555ms/step - loss: 0.1438 - accuracy: 0.9530 - val_loss: 0.8866 - val_accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hXeW0NQa3OP",
    "outputId": "ea471ce8-85c1-4bd2-b4a5-34f4cf706c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "The predicted class is: No_tumer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the new image\n",
    "img_path = '/content/images_medium_radiol.14140130.fig8a.gif'  # Replace with the path to your image\n",
    "img = image.load_img(img_path, target_size=(250,250))  # Adjust target_size based on your model's input size\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0  # Normalize the pixel values to be between 0 and 1\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Decode the predictions\n",
    "class_labels = ['No_tumer', 'glioma', 'meningioma', 'pituitary']  # Replace with your actual class labels\n",
    "predicted_class = class_labels[np.argmax(predictions)]\n",
    "\n",
    "print(f'The predicted class is: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wc28RkdxsteD",
    "outputId": "7f596bc8-2e4a-4535-864c-757c4dd64c22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model \n",
    "model.save(\"brain_tumer.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzJuKSJmcz4v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
