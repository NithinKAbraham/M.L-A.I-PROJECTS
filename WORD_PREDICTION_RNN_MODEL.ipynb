{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yRYw6vTdv2-6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/IndiaUS.txt','r',encoding='utf-8') as myfile:\n",
        "  mytext=myfile.read()"
      ],
      "metadata": {
        "id": "du_3fIgzyZoB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mytext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivi03JSbzFJb",
        "outputId": "e3e1e24e-44a4-420b-db89-da10b9eca03d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Following a lavish state visit by Indian Prime Minister Narendra Modi to Washington, US President Joe Biden has called his country's partnership with India among the \"most consequential in the world\". The BBC's Vikas Pandey and Soutik Biswas explore the factors that contribute to the visit's potential in strengthening the ties between the two nations.\n",
            "\n",
            "The US's relationship with India - the world's most populous country - is \"stronger, closer and more dynamic than any time in history\", Mr Biden said at the completion of a pomp-filled state visit by Mr Modi to the White House.\n",
            "\n",
            "The remark may not be an exaggeration. \"This summit suggests that the relationship has been transformed. It underscores just how broad and deep it has become in a relatively short time,\" says Michael Kugelman of The Wilson Center, an American think-tank.\n",
            "\n",
            "A key reason is that Washington is keen to draw India closer so that it can act as a counterbalance to China's growing influence in the Indo-Pacific. India-US ties had not lived up to their promise following a landmark civilian nuclear deal in 2005 because a liability law passed by India three years later hobbled purchase of reactors.\n",
            "\n",
            "\"This followed a fading commitment to the relationship during [former prime minister] Manmohan Singh's second term as the leader of a coalition government. With Mr Modi there has been a lot more enthusiasm about embracing the US. Mr Biden has also given an overall broad directive to make it work,\" says Seema Sirohi, author of Friends With Benefits: The India-US Story.\n",
            "\n",
            "Ms Sirohi says the US put in a \"lot of effort to make Mr Modi's visit substantive and have a lot of deliverables\". Defence-industrial cooperation and technology topped the list. Consider this:\n",
            "\n",
            "General Electric and India's state-owned Hindustan Aeronautics Limited will make in India advanced fighter jet engines for the country's indigenous light combat aircraft. This means a \"greater transfer of US jet engine technology than ever before\" - a clear sign that Washington not only wants to sell arms to India but is also comfortable with sharing military technology.\n",
            "India will proceed with a $3bn purchase of the battle-tested MQ-9B Predator drones from General Atomics, which will also set up a facility in India. The drones will be assembled in India, which fits into Mr Modi's 'Make in India' campaign. The US supplies only 11% of India's arms - Russia is the biggest (45%) supplier - but hopes to become the primary provider in the coming years. Mr Kugelman says Washington's immediate goal is to \"strengthen India's military capacity to counter China\".\n",
            "Mr Modi wants to make India a semiconductor base. US memory chip giant Micron Technology will invest up to $825m to build a semiconductor assembly and test facility in India, creating thousands of jobs.\n",
            "US semiconductor equipment maker Lam Research will train 60,000 Indian engineers through a network of interconnected labs and research centres to speed up India's semiconductor education and workforce development. Also Applied Materials, the biggest maker of machines for producing semiconductors, will invest $400m to establish an engineering centre in India.\n",
            "\"It is all about the future now. Both sides are talking about cutting-edge technologies and how to seed and shape the future,\" says Ms Sirohi.\n",
            "\n",
            ": U.S. President Joe Biden and first lady Jill Biden welcome India Prime Minister Narendra Modi to the White House on June 21, 2023 in Washington, DC\n",
            "Mr Biden and Mrs Biden welcome Mr Modi to the White House\n",
            "The India-US relationship has seen many ups and downs since the US seriously began courting India - first under President Bill Clinton and then under the George Bush administration. The response from India was measured, never overeager or too forthcoming.\n",
            "\n",
            "The reason was the way India saw geopolitics and its own place in the global order. The strategy of nonalignment, started by India's first prime minister Jawaharlal Nehru, has always been deeply rooted into India's foreign policy.\n",
            "\n",
            "India never wanted to be seen in one camp or the other, or to be seen as junior strategic partner to a global superpower. Mr Modi has not left the ideals of what some describe as \"strategic altruism\" in Indian foreign policy.\n",
            "\n",
            "But Mr Modi is leading a different kind of India, one which has considerably more economic and geopolitical heft. He has owned the India-US relations - he formed close bonds with former presidents Barack Obama and Donald Trump and now with Mr Biden.\n",
            "\n",
            "But India's \"strategic autonomy\" has not been sacrificed. Washington would have wanted India to go a step further on Russia and probably take a harder public stand on China.\n",
            "\n",
            "But the Biden administration didn't seem disappointed as Mr Modi repeated his line that \"this was not the era of war\" without mentioning Russia. The Indian prime minister did speak about the importance of beefing up humanitarian assistance to Ukraine. He didn't mention China by name either but did talk about the importance of a free and prosperous Indo-Pacific.\n",
            "\n",
            "This is how far Mr Modi could have pushed his administration's policy without compromising on strategic autonomy. It may not have been the ideal way for Washington but it didn't come in the way of making Mr Modi's visit a success.\n",
            "\n",
            "The United States Air Force (USAF) and Indian Air Force (IAF) personnel are posing in front of a United States Air Force (USAF) F-15 Eagle fighter jet during the joint 'Exercise Cope India 2023' at the air force station in Kalaikunda, around 170 km west of Kolkata, on April 24th, 2023. \n",
            "US and Indian air force personnel pose in front of a US fighter jet during a joint exercise in India in April\n",
            "\"The two militaries are working more closely together. They now have arrangements in place where they could use each other's facilities for refuelling and maintenance purposes. They are holding joint exercises and they're sharing a lot more intelligence. Credit to Mr Modi for managing to really test the limits of strategic autonomy. In the sense that he is getting about as close as you can to a major power without signing on to a full-fledged alliance,\" Mr Kugelman says.\n",
            "\n",
            "India and the US have had major trade differences in recent years over tariffs. Trade relations particularly suffered during the Trump administration.\n",
            "\n",
            "The two sides were not expected to announce anything major in trade as it was understood that the discussions over that could continue later without overshadowing the visit.\n",
            "\n",
            "But surprisingly, the two sides announced that six separate trade disputes at the World Trade Organization were resolved, including one that involved tariffs.\n",
            "\n",
            "The US is now India's top trading partner at $130bn in goods and Delhi is Washington's eighth largest partner. While these numbers are impressive, analysts and policymakers feel there is a huge untapped potential. India is also a burgeoning market with an expanding middle class and it's been positioning itself as an alternative to China to become a manufacturing hub for the world.\n",
            "\n",
            "President Joe Biden and Indian Prime Minister Narendra Modi participate in an arrival ceremony on the South Lawn of the White House on Thursday, June 22, 2023 in Washington, DC. President Biden is the first U.S. President to invite Prime Minister Modi for an official state visit\n",
            "Some 2.7 million Indians live in the US\n",
            "Many global firms and nations are interested in the proposal as they look to free the global supply chain from China's dominance. In that context, the resolution of trade disputes will give further impetus to unlocking the full potential of India-US trade ties. Mr Modi has said that \"even sky is not the limit (for India-US) ties\".\n",
            "\n",
            "Critics in Washington have questioned India's \"democratic backsliding\" under Mr Modi and his Hindu nationalist Bharatiya Janata Party (BJP). Mr Obama, in a television interview this week, emphasised the significance of addressing the \"protection of the Muslim minority in a predominantly Hindu India\" during discussions between Mr Biden and Mr Modi. \"The progressives in the Democratic Party are disturbed by what is happening in India. The realists and centrists are all for strengthening the relationship because of the China factor,\" says Ms Sirohi.\n",
            "\n",
            "But on the whole, there is a bipartisan agreement to make the relationship deeper and broader. \"The India-US strategic partnership has certainly moved to the next level. It's one of mutual need and mutual benefit,\" says Ms Sirohi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mytokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "Xul2TXIbzH-6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mytokenizer.fit_on_texts([mytext])"
      ],
      "metadata": {
        "id": "7N8qV-j-zioM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words=len(mytokenizer.word_index)+1 # space for extra word out of vocabulary token\n",
        "total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f28_sgfYzpg-",
        "outputId": "8a064d88-fe3b-477e-9fa2-0d39763a25db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "599"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mytokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLb3croy0KLB",
        "outputId": "120a4eff-3da9-4002-bb2e-26f3e2e374a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'to': 2,\n",
              " 'in': 3,\n",
              " 'a': 4,\n",
              " 'and': 5,\n",
              " 'india': 6,\n",
              " 'of': 7,\n",
              " 'mr': 8,\n",
              " 'us': 9,\n",
              " 'is': 10,\n",
              " 'modi': 11,\n",
              " 'has': 12,\n",
              " 'that': 13,\n",
              " 'biden': 14,\n",
              " 'as': 15,\n",
              " 'with': 16,\n",
              " 'not': 17,\n",
              " \"india's\": 18,\n",
              " 'for': 19,\n",
              " 'but': 20,\n",
              " 'on': 21,\n",
              " 'washington': 22,\n",
              " 'an': 23,\n",
              " 'it': 24,\n",
              " 'says': 25,\n",
              " 'will': 26,\n",
              " 'are': 27,\n",
              " 'indian': 28,\n",
              " 'prime': 29,\n",
              " 'minister': 30,\n",
              " 'this': 31,\n",
              " 'have': 32,\n",
              " 'trade': 33,\n",
              " 'visit': 34,\n",
              " 'by': 35,\n",
              " 'president': 36,\n",
              " 'relationship': 37,\n",
              " 'been': 38,\n",
              " 'about': 39,\n",
              " 'strategic': 40,\n",
              " 'more': 41,\n",
              " 'up': 42,\n",
              " 'during': 43,\n",
              " 'also': 44,\n",
              " 'make': 45,\n",
              " 'sirohi': 46,\n",
              " 'china': 47,\n",
              " 'air': 48,\n",
              " 'force': 49,\n",
              " 'state': 50,\n",
              " 'his': 51,\n",
              " 'ties': 52,\n",
              " 'two': 53,\n",
              " 'at': 54,\n",
              " 'white': 55,\n",
              " 'house': 56,\n",
              " 'be': 57,\n",
              " 'lot': 58,\n",
              " 'ms': 59,\n",
              " 'technology': 60,\n",
              " 'jet': 61,\n",
              " 'semiconductor': 62,\n",
              " 'now': 63,\n",
              " 'first': 64,\n",
              " 'was': 65,\n",
              " 'global': 66,\n",
              " 'one': 67,\n",
              " 'he': 68,\n",
              " 'without': 69,\n",
              " 'they': 70,\n",
              " 'narendra': 71,\n",
              " 'joe': 72,\n",
              " 'world': 73,\n",
              " 'potential': 74,\n",
              " 'how': 75,\n",
              " 'become': 76,\n",
              " 'kugelman': 77,\n",
              " 'years': 78,\n",
              " 'there': 79,\n",
              " \"modi's\": 80,\n",
              " 'fighter': 81,\n",
              " 'from': 82,\n",
              " 'which': 83,\n",
              " 'russia': 84,\n",
              " 'sides': 85,\n",
              " '2023': 86,\n",
              " 'seen': 87,\n",
              " 'under': 88,\n",
              " 'administration': 89,\n",
              " 'or': 90,\n",
              " 'way': 91,\n",
              " 'policy': 92,\n",
              " 'partner': 93,\n",
              " 'autonomy': 94,\n",
              " \"didn't\": 95,\n",
              " 'could': 96,\n",
              " 'joint': 97,\n",
              " 'major': 98,\n",
              " 'following': 99,\n",
              " \"country's\": 100,\n",
              " 'partnership': 101,\n",
              " 'most': 102,\n",
              " 'strengthening': 103,\n",
              " 'between': 104,\n",
              " 'nations': 105,\n",
              " 'closer': 106,\n",
              " 'than': 107,\n",
              " 'time': 108,\n",
              " 'said': 109,\n",
              " 'may': 110,\n",
              " 'broad': 111,\n",
              " 'reason': 112,\n",
              " 'can': 113,\n",
              " \"china's\": 114,\n",
              " 'indo': 115,\n",
              " 'pacific': 116,\n",
              " 'had': 117,\n",
              " 'because': 118,\n",
              " 'later': 119,\n",
              " 'purchase': 120,\n",
              " 'former': 121,\n",
              " 'general': 122,\n",
              " 'owned': 123,\n",
              " 'only': 124,\n",
              " 'wants': 125,\n",
              " 'arms': 126,\n",
              " 'sharing': 127,\n",
              " 'military': 128,\n",
              " 'drones': 129,\n",
              " 'facility': 130,\n",
              " 'into': 131,\n",
              " 'biggest': 132,\n",
              " \"washington's\": 133,\n",
              " 'invest': 134,\n",
              " 'test': 135,\n",
              " 'maker': 136,\n",
              " 'research': 137,\n",
              " 'all': 138,\n",
              " 'future': 139,\n",
              " 'u': 140,\n",
              " 's': 141,\n",
              " 'welcome': 142,\n",
              " 'june': 143,\n",
              " 'dc': 144,\n",
              " 'many': 145,\n",
              " 'never': 146,\n",
              " 'place': 147,\n",
              " 'foreign': 148,\n",
              " 'wanted': 149,\n",
              " 'what': 150,\n",
              " 'some': 151,\n",
              " 'relations': 152,\n",
              " 'close': 153,\n",
              " 'obama': 154,\n",
              " 'trump': 155,\n",
              " 'further': 156,\n",
              " 'did': 157,\n",
              " 'importance': 158,\n",
              " 'free': 159,\n",
              " 'united': 160,\n",
              " 'states': 161,\n",
              " 'usaf': 162,\n",
              " 'personnel': 163,\n",
              " 'front': 164,\n",
              " 'april': 165,\n",
              " 'full': 166,\n",
              " 'over': 167,\n",
              " 'tariffs': 168,\n",
              " 'were': 169,\n",
              " 'discussions': 170,\n",
              " 'disputes': 171,\n",
              " \"it's\": 172,\n",
              " 'democratic': 173,\n",
              " 'hindu': 174,\n",
              " 'party': 175,\n",
              " 'mutual': 176,\n",
              " 'lavish': 177,\n",
              " 'called': 178,\n",
              " 'among': 179,\n",
              " 'consequential': 180,\n",
              " \"bbc's\": 181,\n",
              " 'vikas': 182,\n",
              " 'pandey': 183,\n",
              " 'soutik': 184,\n",
              " 'biswas': 185,\n",
              " 'explore': 186,\n",
              " 'factors': 187,\n",
              " 'contribute': 188,\n",
              " \"visit's\": 189,\n",
              " \"us's\": 190,\n",
              " \"world's\": 191,\n",
              " 'populous': 192,\n",
              " 'country': 193,\n",
              " 'stronger': 194,\n",
              " 'dynamic': 195,\n",
              " 'any': 196,\n",
              " 'history': 197,\n",
              " 'completion': 198,\n",
              " 'pomp': 199,\n",
              " 'filled': 200,\n",
              " 'remark': 201,\n",
              " 'exaggeration': 202,\n",
              " 'summit': 203,\n",
              " 'suggests': 204,\n",
              " 'transformed': 205,\n",
              " 'underscores': 206,\n",
              " 'just': 207,\n",
              " 'deep': 208,\n",
              " 'relatively': 209,\n",
              " 'short': 210,\n",
              " 'michael': 211,\n",
              " 'wilson': 212,\n",
              " 'center': 213,\n",
              " 'american': 214,\n",
              " 'think': 215,\n",
              " 'tank': 216,\n",
              " 'key': 217,\n",
              " 'keen': 218,\n",
              " 'draw': 219,\n",
              " 'so': 220,\n",
              " 'act': 221,\n",
              " 'counterbalance': 222,\n",
              " 'growing': 223,\n",
              " 'influence': 224,\n",
              " 'lived': 225,\n",
              " 'their': 226,\n",
              " 'promise': 227,\n",
              " 'landmark': 228,\n",
              " 'civilian': 229,\n",
              " 'nuclear': 230,\n",
              " 'deal': 231,\n",
              " '2005': 232,\n",
              " 'liability': 233,\n",
              " 'law': 234,\n",
              " 'passed': 235,\n",
              " 'three': 236,\n",
              " 'hobbled': 237,\n",
              " 'reactors': 238,\n",
              " 'followed': 239,\n",
              " 'fading': 240,\n",
              " 'commitment': 241,\n",
              " 'manmohan': 242,\n",
              " \"singh's\": 243,\n",
              " 'second': 244,\n",
              " 'term': 245,\n",
              " 'leader': 246,\n",
              " 'coalition': 247,\n",
              " 'government': 248,\n",
              " 'enthusiasm': 249,\n",
              " 'embracing': 250,\n",
              " 'given': 251,\n",
              " 'overall': 252,\n",
              " 'directive': 253,\n",
              " 'work': 254,\n",
              " 'seema': 255,\n",
              " 'author': 256,\n",
              " 'friends': 257,\n",
              " 'benefits': 258,\n",
              " 'story': 259,\n",
              " 'put': 260,\n",
              " 'effort': 261,\n",
              " 'substantive': 262,\n",
              " 'deliverables': 263,\n",
              " 'defence': 264,\n",
              " 'industrial': 265,\n",
              " 'cooperation': 266,\n",
              " 'topped': 267,\n",
              " 'list': 268,\n",
              " 'consider': 269,\n",
              " 'electric': 270,\n",
              " 'hindustan': 271,\n",
              " 'aeronautics': 272,\n",
              " 'limited': 273,\n",
              " 'advanced': 274,\n",
              " 'engines': 275,\n",
              " 'indigenous': 276,\n",
              " 'light': 277,\n",
              " 'combat': 278,\n",
              " 'aircraft': 279,\n",
              " 'means': 280,\n",
              " 'greater': 281,\n",
              " 'transfer': 282,\n",
              " 'engine': 283,\n",
              " 'ever': 284,\n",
              " 'before': 285,\n",
              " 'clear': 286,\n",
              " 'sign': 287,\n",
              " 'sell': 288,\n",
              " 'comfortable': 289,\n",
              " 'proceed': 290,\n",
              " '3bn': 291,\n",
              " 'battle': 292,\n",
              " 'tested': 293,\n",
              " 'mq': 294,\n",
              " '9b': 295,\n",
              " 'predator': 296,\n",
              " 'atomics': 297,\n",
              " 'set': 298,\n",
              " 'assembled': 299,\n",
              " 'fits': 300,\n",
              " \"'make\": 301,\n",
              " \"india'\": 302,\n",
              " 'campaign': 303,\n",
              " 'supplies': 304,\n",
              " '11': 305,\n",
              " '45': 306,\n",
              " 'supplier': 307,\n",
              " 'hopes': 308,\n",
              " 'primary': 309,\n",
              " 'provider': 310,\n",
              " 'coming': 311,\n",
              " 'immediate': 312,\n",
              " 'goal': 313,\n",
              " 'strengthen': 314,\n",
              " 'capacity': 315,\n",
              " 'counter': 316,\n",
              " 'base': 317,\n",
              " 'memory': 318,\n",
              " 'chip': 319,\n",
              " 'giant': 320,\n",
              " 'micron': 321,\n",
              " '825m': 322,\n",
              " 'build': 323,\n",
              " 'assembly': 324,\n",
              " 'creating': 325,\n",
              " 'thousands': 326,\n",
              " 'jobs': 327,\n",
              " 'equipment': 328,\n",
              " 'lam': 329,\n",
              " 'train': 330,\n",
              " '60': 331,\n",
              " '000': 332,\n",
              " 'engineers': 333,\n",
              " 'through': 334,\n",
              " 'network': 335,\n",
              " 'interconnected': 336,\n",
              " 'labs': 337,\n",
              " 'centres': 338,\n",
              " 'speed': 339,\n",
              " 'education': 340,\n",
              " 'workforce': 341,\n",
              " 'development': 342,\n",
              " 'applied': 343,\n",
              " 'materials': 344,\n",
              " 'machines': 345,\n",
              " 'producing': 346,\n",
              " 'semiconductors': 347,\n",
              " '400m': 348,\n",
              " 'establish': 349,\n",
              " 'engineering': 350,\n",
              " 'centre': 351,\n",
              " 'both': 352,\n",
              " 'talking': 353,\n",
              " 'cutting': 354,\n",
              " 'edge': 355,\n",
              " 'technologies': 356,\n",
              " 'seed': 357,\n",
              " 'shape': 358,\n",
              " 'lady': 359,\n",
              " 'jill': 360,\n",
              " '21': 361,\n",
              " 'mrs': 362,\n",
              " 'ups': 363,\n",
              " 'downs': 364,\n",
              " 'since': 365,\n",
              " 'seriously': 366,\n",
              " 'began': 367,\n",
              " 'courting': 368,\n",
              " 'bill': 369,\n",
              " 'clinton': 370,\n",
              " 'then': 371,\n",
              " 'george': 372,\n",
              " 'bush': 373,\n",
              " 'response': 374,\n",
              " 'measured': 375,\n",
              " 'overeager': 376,\n",
              " 'too': 377,\n",
              " 'forthcoming': 378,\n",
              " 'saw': 379,\n",
              " 'geopolitics': 380,\n",
              " 'its': 381,\n",
              " 'own': 382,\n",
              " 'order': 383,\n",
              " 'strategy': 384,\n",
              " 'nonalignment': 385,\n",
              " 'started': 386,\n",
              " 'jawaharlal': 387,\n",
              " 'nehru': 388,\n",
              " 'always': 389,\n",
              " 'deeply': 390,\n",
              " 'rooted': 391,\n",
              " 'camp': 392,\n",
              " 'other': 393,\n",
              " 'junior': 394,\n",
              " 'superpower': 395,\n",
              " 'left': 396,\n",
              " 'ideals': 397,\n",
              " 'describe': 398,\n",
              " 'altruism': 399,\n",
              " 'leading': 400,\n",
              " 'different': 401,\n",
              " 'kind': 402,\n",
              " 'considerably': 403,\n",
              " 'economic': 404,\n",
              " 'geopolitical': 405,\n",
              " 'heft': 406,\n",
              " 'formed': 407,\n",
              " 'bonds': 408,\n",
              " 'presidents': 409,\n",
              " 'barack': 410,\n",
              " 'donald': 411,\n",
              " 'sacrificed': 412,\n",
              " 'would': 413,\n",
              " 'go': 414,\n",
              " 'step': 415,\n",
              " 'probably': 416,\n",
              " 'take': 417,\n",
              " 'harder': 418,\n",
              " 'public': 419,\n",
              " 'stand': 420,\n",
              " 'seem': 421,\n",
              " 'disappointed': 422,\n",
              " 'repeated': 423,\n",
              " 'line': 424,\n",
              " 'era': 425,\n",
              " 'war': 426,\n",
              " 'mentioning': 427,\n",
              " 'speak': 428,\n",
              " 'beefing': 429,\n",
              " 'humanitarian': 430,\n",
              " 'assistance': 431,\n",
              " 'ukraine': 432,\n",
              " 'mention': 433,\n",
              " 'name': 434,\n",
              " 'either': 435,\n",
              " 'talk': 436,\n",
              " 'prosperous': 437,\n",
              " 'far': 438,\n",
              " 'pushed': 439,\n",
              " \"administration's\": 440,\n",
              " 'compromising': 441,\n",
              " 'ideal': 442,\n",
              " 'come': 443,\n",
              " 'making': 444,\n",
              " 'success': 445,\n",
              " 'iaf': 446,\n",
              " 'posing': 447,\n",
              " 'f': 448,\n",
              " '15': 449,\n",
              " 'eagle': 450,\n",
              " \"'exercise\": 451,\n",
              " 'cope': 452,\n",
              " \"2023'\": 453,\n",
              " 'station': 454,\n",
              " 'kalaikunda': 455,\n",
              " 'around': 456,\n",
              " '170': 457,\n",
              " 'km': 458,\n",
              " 'west': 459,\n",
              " 'kolkata': 460,\n",
              " '24th': 461,\n",
              " 'pose': 462,\n",
              " 'exercise': 463,\n",
              " 'militaries': 464,\n",
              " 'working': 465,\n",
              " 'closely': 466,\n",
              " 'together': 467,\n",
              " 'arrangements': 468,\n",
              " 'where': 469,\n",
              " 'use': 470,\n",
              " 'each': 471,\n",
              " \"other's\": 472,\n",
              " 'facilities': 473,\n",
              " 'refuelling': 474,\n",
              " 'maintenance': 475,\n",
              " 'purposes': 476,\n",
              " 'holding': 477,\n",
              " 'exercises': 478,\n",
              " \"they're\": 479,\n",
              " 'intelligence': 480,\n",
              " 'credit': 481,\n",
              " 'managing': 482,\n",
              " 'really': 483,\n",
              " 'limits': 484,\n",
              " 'sense': 485,\n",
              " 'getting': 486,\n",
              " 'you': 487,\n",
              " 'power': 488,\n",
              " 'signing': 489,\n",
              " 'fledged': 490,\n",
              " 'alliance': 491,\n",
              " 'differences': 492,\n",
              " 'recent': 493,\n",
              " 'particularly': 494,\n",
              " 'suffered': 495,\n",
              " 'expected': 496,\n",
              " 'announce': 497,\n",
              " 'anything': 498,\n",
              " 'understood': 499,\n",
              " 'continue': 500,\n",
              " 'overshadowing': 501,\n",
              " 'surprisingly': 502,\n",
              " 'announced': 503,\n",
              " 'six': 504,\n",
              " 'separate': 505,\n",
              " 'organization': 506,\n",
              " 'resolved': 507,\n",
              " 'including': 508,\n",
              " 'involved': 509,\n",
              " 'top': 510,\n",
              " 'trading': 511,\n",
              " '130bn': 512,\n",
              " 'goods': 513,\n",
              " 'delhi': 514,\n",
              " 'eighth': 515,\n",
              " 'largest': 516,\n",
              " 'while': 517,\n",
              " 'these': 518,\n",
              " 'numbers': 519,\n",
              " 'impressive': 520,\n",
              " 'analysts': 521,\n",
              " 'policymakers': 522,\n",
              " 'feel': 523,\n",
              " 'huge': 524,\n",
              " 'untapped': 525,\n",
              " 'burgeoning': 526,\n",
              " 'market': 527,\n",
              " 'expanding': 528,\n",
              " 'middle': 529,\n",
              " 'class': 530,\n",
              " 'positioning': 531,\n",
              " 'itself': 532,\n",
              " 'alternative': 533,\n",
              " 'manufacturing': 534,\n",
              " 'hub': 535,\n",
              " 'participate': 536,\n",
              " 'arrival': 537,\n",
              " 'ceremony': 538,\n",
              " 'south': 539,\n",
              " 'lawn': 540,\n",
              " 'thursday': 541,\n",
              " '22': 542,\n",
              " 'invite': 543,\n",
              " 'official': 544,\n",
              " '2': 545,\n",
              " '7': 546,\n",
              " 'million': 547,\n",
              " 'indians': 548,\n",
              " 'live': 549,\n",
              " 'firms': 550,\n",
              " 'interested': 551,\n",
              " 'proposal': 552,\n",
              " 'look': 553,\n",
              " 'supply': 554,\n",
              " 'chain': 555,\n",
              " 'dominance': 556,\n",
              " 'context': 557,\n",
              " 'resolution': 558,\n",
              " 'give': 559,\n",
              " 'impetus': 560,\n",
              " 'unlocking': 561,\n",
              " 'even': 562,\n",
              " 'sky': 563,\n",
              " 'limit': 564,\n",
              " 'critics': 565,\n",
              " 'questioned': 566,\n",
              " 'backsliding': 567,\n",
              " 'nationalist': 568,\n",
              " 'bharatiya': 569,\n",
              " 'janata': 570,\n",
              " 'bjp': 571,\n",
              " 'television': 572,\n",
              " 'interview': 573,\n",
              " 'week': 574,\n",
              " 'emphasised': 575,\n",
              " 'significance': 576,\n",
              " 'addressing': 577,\n",
              " 'protection': 578,\n",
              " 'muslim': 579,\n",
              " 'minority': 580,\n",
              " 'predominantly': 581,\n",
              " 'progressives': 582,\n",
              " 'disturbed': 583,\n",
              " 'happening': 584,\n",
              " 'realists': 585,\n",
              " 'centrists': 586,\n",
              " 'factor': 587,\n",
              " 'whole': 588,\n",
              " 'bipartisan': 589,\n",
              " 'agreement': 590,\n",
              " 'deeper': 591,\n",
              " 'broader': 592,\n",
              " 'certainly': 593,\n",
              " 'moved': 594,\n",
              " 'next': 595,\n",
              " 'level': 596,\n",
              " 'need': 597,\n",
              " 'benefit': 598}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('tokenizer.pickle','wb') as handle:\n",
        "  pickle.dump(mytokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "aJcbMxeP0Tpp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_input_sequences=[]\n",
        "for line in mytext.split('\\n'):\n",
        "  token_list=mytokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "  print(token_list)\n",
        "\n",
        "\n",
        "  for i in range(1,len(token_list)):\n",
        "    #n gram sequences\n",
        "    my_ngram_sequence=token_list[:i+1]\n",
        "    my_input_sequences.append(my_ngram_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVNiwhNF1rt-",
        "outputId": "a210fe39-41f6-469c-b8a9-ab838098cd23"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[99, 4, 177, 50, 34, 35, 28, 29, 30, 71, 11, 2, 22, 9, 36, 72, 14, 12, 178, 51, 100, 101, 16, 6, 179, 1, 102, 180, 3, 1, 73, 1, 181, 182, 183, 5, 184, 185, 186, 1, 187, 13, 188, 2, 1, 189, 74, 3, 103, 1, 52, 104, 1, 53, 105]\n",
            "[]\n",
            "[1, 190, 37, 16, 6, 1, 191, 102, 192, 193, 10, 194, 106, 5, 41, 195, 107, 196, 108, 3, 197, 8, 14, 109, 54, 1, 198, 7, 4, 199, 200, 50, 34, 35, 8, 11, 2, 1, 55, 56]\n",
            "[]\n",
            "[1, 201, 110, 17, 57, 23, 202, 31, 203, 204, 13, 1, 37, 12, 38, 205, 24, 206, 207, 75, 111, 5, 208, 24, 12, 76, 3, 4, 209, 210, 108, 25, 211, 77, 7, 1, 212, 213, 23, 214, 215, 216]\n",
            "[]\n",
            "[4, 217, 112, 10, 13, 22, 10, 218, 2, 219, 6, 106, 220, 13, 24, 113, 221, 15, 4, 222, 2, 114, 223, 224, 3, 1, 115, 116, 6, 9, 52, 117, 17, 225, 42, 2, 226, 227, 99, 4, 228, 229, 230, 231, 3, 232, 118, 4, 233, 234, 235, 35, 6, 236, 78, 119, 237, 120, 7, 238]\n",
            "[]\n",
            "[31, 239, 4, 240, 241, 2, 1, 37, 43, 121, 29, 30, 242, 243, 244, 245, 15, 1, 246, 7, 4, 247, 248, 16, 8, 11, 79, 12, 38, 4, 58, 41, 249, 39, 250, 1, 9, 8, 14, 12, 44, 251, 23, 252, 111, 253, 2, 45, 24, 254, 25, 255, 46, 256, 7, 257, 16, 258, 1, 6, 9, 259]\n",
            "[]\n",
            "[59, 46, 25, 1, 9, 260, 3, 4, 58, 7, 261, 2, 45, 8, 80, 34, 262, 5, 32, 4, 58, 7, 263, 264, 265, 266, 5, 60, 267, 1, 268, 269, 31]\n",
            "[]\n",
            "[122, 270, 5, 18, 50, 123, 271, 272, 273, 26, 45, 3, 6, 274, 81, 61, 275, 19, 1, 100, 276, 277, 278, 279, 31, 280, 4, 281, 282, 7, 9, 61, 283, 60, 107, 284, 285, 4, 286, 287, 13, 22, 17, 124, 125, 2, 288, 126, 2, 6, 20, 10, 44, 289, 16, 127, 128, 60]\n",
            "[6, 26, 290, 16, 4, 291, 120, 7, 1, 292, 293, 294, 295, 296, 129, 82, 122, 297, 83, 26, 44, 298, 42, 4, 130, 3, 6, 1, 129, 26, 57, 299, 3, 6, 83, 300, 131, 8, 80, 301, 3, 302, 303, 1, 9, 304, 124, 305, 7, 18, 126, 84, 10, 1, 132, 306, 307, 20, 308, 2, 76, 1, 309, 310, 3, 1, 311, 78, 8, 77, 25, 133, 312, 313, 10, 2, 314, 18, 128, 315, 2, 316, 47]\n",
            "[8, 11, 125, 2, 45, 6, 4, 62, 317, 9, 318, 319, 320, 321, 60, 26, 134, 42, 2, 322, 2, 323, 4, 62, 324, 5, 135, 130, 3, 6, 325, 326, 7, 327]\n",
            "[9, 62, 328, 136, 329, 137, 26, 330, 331, 332, 28, 333, 334, 4, 335, 7, 336, 337, 5, 137, 338, 2, 339, 42, 18, 62, 340, 5, 341, 342, 44, 343, 344, 1, 132, 136, 7, 345, 19, 346, 347, 26, 134, 348, 2, 349, 23, 350, 351, 3, 6]\n",
            "[24, 10, 138, 39, 1, 139, 63, 352, 85, 27, 353, 39, 354, 355, 356, 5, 75, 2, 357, 5, 358, 1, 139, 25, 59, 46]\n",
            "[]\n",
            "[140, 141, 36, 72, 14, 5, 64, 359, 360, 14, 142, 6, 29, 30, 71, 11, 2, 1, 55, 56, 21, 143, 361, 86, 3, 22, 144]\n",
            "[8, 14, 5, 362, 14, 142, 8, 11, 2, 1, 55, 56]\n",
            "[1, 6, 9, 37, 12, 87, 145, 363, 5, 364, 365, 1, 9, 366, 367, 368, 6, 64, 88, 36, 369, 370, 5, 371, 88, 1, 372, 373, 89, 1, 374, 82, 6, 65, 375, 146, 376, 90, 377, 378]\n",
            "[]\n",
            "[1, 112, 65, 1, 91, 6, 379, 380, 5, 381, 382, 147, 3, 1, 66, 383, 1, 384, 7, 385, 386, 35, 18, 64, 29, 30, 387, 388, 12, 389, 38, 390, 391, 131, 18, 148, 92]\n",
            "[]\n",
            "[6, 146, 149, 2, 57, 87, 3, 67, 392, 90, 1, 393, 90, 2, 57, 87, 15, 394, 40, 93, 2, 4, 66, 395, 8, 11, 12, 17, 396, 1, 397, 7, 150, 151, 398, 15, 40, 399, 3, 28, 148, 92]\n",
            "[]\n",
            "[20, 8, 11, 10, 400, 4, 401, 402, 7, 6, 67, 83, 12, 403, 41, 404, 5, 405, 406, 68, 12, 123, 1, 6, 9, 152, 68, 407, 153, 408, 16, 121, 409, 410, 154, 5, 411, 155, 5, 63, 16, 8, 14]\n",
            "[]\n",
            "[20, 18, 40, 94, 12, 17, 38, 412, 22, 413, 32, 149, 6, 2, 414, 4, 415, 156, 21, 84, 5, 416, 417, 4, 418, 419, 420, 21, 47]\n",
            "[]\n",
            "[20, 1, 14, 89, 95, 421, 422, 15, 8, 11, 423, 51, 424, 13, 31, 65, 17, 1, 425, 7, 426, 69, 427, 84, 1, 28, 29, 30, 157, 428, 39, 1, 158, 7, 429, 42, 430, 431, 2, 432, 68, 95, 433, 47, 35, 434, 435, 20, 157, 436, 39, 1, 158, 7, 4, 159, 5, 437, 115, 116]\n",
            "[]\n",
            "[31, 10, 75, 438, 8, 11, 96, 32, 439, 51, 440, 92, 69, 441, 21, 40, 94, 24, 110, 17, 32, 38, 1, 442, 91, 19, 22, 20, 24, 95, 443, 3, 1, 91, 7, 444, 8, 80, 34, 4, 445]\n",
            "[]\n",
            "[1, 160, 161, 48, 49, 162, 5, 28, 48, 49, 446, 163, 27, 447, 3, 164, 7, 4, 160, 161, 48, 49, 162, 448, 449, 450, 81, 61, 43, 1, 97, 451, 452, 6, 453, 54, 1, 48, 49, 454, 3, 455, 456, 457, 458, 459, 7, 460, 21, 165, 461, 86]\n",
            "[9, 5, 28, 48, 49, 163, 462, 3, 164, 7, 4, 9, 81, 61, 43, 4, 97, 463, 3, 6, 3, 165]\n",
            "[1, 53, 464, 27, 465, 41, 466, 467, 70, 63, 32, 468, 3, 147, 469, 70, 96, 470, 471, 472, 473, 19, 474, 5, 475, 476, 70, 27, 477, 97, 478, 5, 479, 127, 4, 58, 41, 480, 481, 2, 8, 11, 19, 482, 2, 483, 135, 1, 484, 7, 40, 94, 3, 1, 485, 13, 68, 10, 486, 39, 15, 153, 15, 487, 113, 2, 4, 98, 488, 69, 489, 21, 2, 4, 166, 490, 491, 8, 77, 25]\n",
            "[]\n",
            "[6, 5, 1, 9, 32, 117, 98, 33, 492, 3, 493, 78, 167, 168, 33, 152, 494, 495, 43, 1, 155, 89]\n",
            "[]\n",
            "[1, 53, 85, 169, 17, 496, 2, 497, 498, 98, 3, 33, 15, 24, 65, 499, 13, 1, 170, 167, 13, 96, 500, 119, 69, 501, 1, 34]\n",
            "[]\n",
            "[20, 502, 1, 53, 85, 503, 13, 504, 505, 33, 171, 54, 1, 73, 33, 506, 169, 507, 508, 67, 13, 509, 168]\n",
            "[]\n",
            "[1, 9, 10, 63, 18, 510, 511, 93, 54, 512, 3, 513, 5, 514, 10, 133, 515, 516, 93, 517, 518, 519, 27, 520, 521, 5, 522, 523, 79, 10, 4, 524, 525, 74, 6, 10, 44, 4, 526, 527, 16, 23, 528, 529, 530, 5, 172, 38, 531, 532, 15, 23, 533, 2, 47, 2, 76, 4, 534, 535, 19, 1, 73]\n",
            "[]\n",
            "[36, 72, 14, 5, 28, 29, 30, 71, 11, 536, 3, 23, 537, 538, 21, 1, 539, 540, 7, 1, 55, 56, 21, 541, 143, 542, 86, 3, 22, 144, 36, 14, 10, 1, 64, 140, 141, 36, 2, 543, 29, 30, 11, 19, 23, 544, 50, 34]\n",
            "[151, 545, 546, 547, 548, 549, 3, 1, 9]\n",
            "[145, 66, 550, 5, 105, 27, 551, 3, 1, 552, 15, 70, 553, 2, 159, 1, 66, 554, 555, 82, 114, 556, 3, 13, 557, 1, 558, 7, 33, 171, 26, 559, 156, 560, 2, 561, 1, 166, 74, 7, 6, 9, 33, 52, 8, 11, 12, 109, 13, 562, 563, 10, 17, 1, 564, 19, 6, 9, 52]\n",
            "[]\n",
            "[565, 3, 22, 32, 566, 18, 173, 567, 88, 8, 11, 5, 51, 174, 568, 569, 570, 175, 571, 8, 154, 3, 4, 572, 573, 31, 574, 575, 1, 576, 7, 577, 1, 578, 7, 1, 579, 580, 3, 4, 581, 174, 6, 43, 170, 104, 8, 14, 5, 8, 11, 1, 582, 3, 1, 173, 175, 27, 583, 35, 150, 10, 584, 3, 6, 1, 585, 5, 586, 27, 138, 19, 103, 1, 37, 118, 7, 1, 47, 587, 25, 59, 46]\n",
            "[]\n",
            "[20, 21, 1, 588, 79, 10, 4, 589, 590, 2, 45, 1, 37, 591, 5, 592, 1, 6, 9, 40, 101, 12, 593, 594, 2, 1, 595, 596, 172, 67, 7, 176, 597, 5, 176, 598, 25, 59, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len=max([len(seq) for seq in my_input_sequences])\n",
        "max_sequence_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHPhve043ap6",
        "outputId": "5a8c5754-1161-4407-8cc7-8a2a307403fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence=np.array(pad_sequences(my_input_sequences,maxlen=max_sequence_len,padding='pre'))\n",
        "input_sequence\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icYTccZt85pO",
        "outputId": "dd3cf2ef-d197-4580-e989-bedd73d8acca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  99,   4],\n",
              "       [  0,   0,   0, ...,  99,   4, 177],\n",
              "       [  0,   0,   0, ...,   4, 177,  50],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 176, 598,  25],\n",
              "       [  0,   0,   0, ..., 598,  25,  59],\n",
              "       [  0,   0,   0, ...,  25,  59,  46]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=input_sequence[:,:-1]\n",
        "y=input_sequence[:,-1]"
      ],
      "metadata": {
        "id": "zsiwJ80Q41Zc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6WMJ6Qn5ga7",
        "outputId": "8f92db17-65e6-447a-dad8-b433cf98d97a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,  99],\n",
              "       [  0,   0,   0, ...,   0,  99,   4],\n",
              "       [  0,   0,   0, ...,  99,   4, 177],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   5, 176, 598],\n",
              "       [  0,   0,   0, ..., 176, 598,  25],\n",
              "       [  0,   0,   0, ..., 598,  25,  59]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqXzjof75ho8",
        "outputId": "b097dfdf-1fe0-405e-cc79-888bb6e9b432"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  4, 177,  50, ...,  25,  59,  46], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.array(tf.keras.utils.to_categorical(y,num_classes=total_words))\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqO9K6f25kap",
        "outputId": "6cdf7d6e-a8d4-4b69-cf8f-a0e16f0d21b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=total_words,output_dim=100,input_length=max_sequence_len-1))\n",
        "\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words,activation='softmax'))\n"
      ],
      "metadata": {
        "id": "UH5kvx1p7TzE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "TsRJscZ__dbV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=500,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gP-4qlPAinG",
        "outputId": "886ddd98-a1bb-4c6c-d487-fdb18283053e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "43/43 [==============================] - 5s 81ms/step - loss: 0.0259 - accuracy: 0.9876\n",
            "Epoch 2/500\n",
            "43/43 [==============================] - 3s 74ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 3/500\n",
            "43/43 [==============================] - 2s 47ms/step - loss: 0.0265 - accuracy: 0.9861\n",
            "Epoch 4/500\n",
            "43/43 [==============================] - 2s 41ms/step - loss: 0.0263 - accuracy: 0.9861\n",
            "Epoch 5/500\n",
            "43/43 [==============================] - 2s 36ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 6/500\n",
            "43/43 [==============================] - 1s 21ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 7/500\n",
            "43/43 [==============================] - 1s 28ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 8/500\n",
            "43/43 [==============================] - 1s 17ms/step - loss: 0.0263 - accuracy: 0.9854\n",
            "Epoch 9/500\n",
            "43/43 [==============================] - 1s 15ms/step - loss: 0.0260 - accuracy: 0.9861\n",
            "Epoch 10/500\n",
            "43/43 [==============================] - 1s 24ms/step - loss: 0.0260 - accuracy: 0.9861\n",
            "Epoch 11/500\n",
            "43/43 [==============================] - 1s 12ms/step - loss: 0.0265 - accuracy: 0.9861\n",
            "Epoch 12/500\n",
            "43/43 [==============================] - 1s 15ms/step - loss: 0.0265 - accuracy: 0.9869\n",
            "Epoch 13/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9854\n",
            "Epoch 14/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9869\n",
            "Epoch 15/500\n",
            "43/43 [==============================] - 1s 18ms/step - loss: 0.0264 - accuracy: 0.9854\n",
            "Epoch 16/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9854\n",
            "Epoch 17/500\n",
            "43/43 [==============================] - 1s 16ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 18/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9876\n",
            "Epoch 19/500\n",
            "43/43 [==============================] - 1s 16ms/step - loss: 0.0260 - accuracy: 0.9847\n",
            "Epoch 20/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9861\n",
            "Epoch 21/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 22/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9869\n",
            "Epoch 23/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9854\n",
            "Epoch 24/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 25/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9861\n",
            "Epoch 26/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 27/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9854\n",
            "Epoch 28/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9876\n",
            "Epoch 29/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 30/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9876\n",
            "Epoch 31/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9847\n",
            "Epoch 32/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9869\n",
            "Epoch 33/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 34/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9847\n",
            "Epoch 35/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 36/500\n",
            "43/43 [==============================] - 1s 13ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 37/500\n",
            "43/43 [==============================] - 1s 14ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 38/500\n",
            "43/43 [==============================] - 1s 14ms/step - loss: 0.0260 - accuracy: 0.9847\n",
            "Epoch 39/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9861\n",
            "Epoch 40/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9840\n",
            "Epoch 41/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 42/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9854\n",
            "Epoch 43/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 44/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 45/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9876\n",
            "Epoch 46/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 47/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9869\n",
            "Epoch 48/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9840\n",
            "Epoch 49/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 50/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 51/500\n",
            "43/43 [==============================] - 1s 12ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 52/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9854\n",
            "Epoch 53/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9869\n",
            "Epoch 54/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9876\n",
            "Epoch 55/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0263 - accuracy: 0.9854\n",
            "Epoch 56/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9861\n",
            "Epoch 57/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 58/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 59/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9854\n",
            "Epoch 60/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0264 - accuracy: 0.9854\n",
            "Epoch 61/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 62/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9847\n",
            "Epoch 63/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 64/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 65/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 66/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9861\n",
            "Epoch 67/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 68/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9883\n",
            "Epoch 69/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0261 - accuracy: 0.9861\n",
            "Epoch 70/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 71/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9847\n",
            "Epoch 72/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9869\n",
            "Epoch 73/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 74/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 75/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 76/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 77/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 78/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 79/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9869\n",
            "Epoch 80/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 81/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 82/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9861\n",
            "Epoch 83/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9847\n",
            "Epoch 84/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9854\n",
            "Epoch 85/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 86/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 87/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9847\n",
            "Epoch 88/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 89/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9869\n",
            "Epoch 90/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9876\n",
            "Epoch 91/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9869\n",
            "Epoch 92/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 93/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 94/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 95/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9854\n",
            "Epoch 96/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 97/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 98/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 99/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9847\n",
            "Epoch 100/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9854\n",
            "Epoch 101/500\n",
            "43/43 [==============================] - 1s 13ms/step - loss: 0.0254 - accuracy: 0.9847\n",
            "Epoch 102/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9861\n",
            "Epoch 103/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 104/500\n",
            "43/43 [==============================] - 1s 13ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 105/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 106/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 107/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9847\n",
            "Epoch 108/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9861\n",
            "Epoch 109/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9854\n",
            "Epoch 110/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 111/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9861\n",
            "Epoch 112/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9869\n",
            "Epoch 113/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9847\n",
            "Epoch 114/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9847\n",
            "Epoch 115/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9869\n",
            "Epoch 116/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9847\n",
            "Epoch 117/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9847\n",
            "Epoch 118/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9876\n",
            "Epoch 119/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 120/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 121/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 122/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9847\n",
            "Epoch 123/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 124/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9854\n",
            "Epoch 125/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 126/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9854\n",
            "Epoch 127/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 128/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 129/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 130/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 131/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9869\n",
            "Epoch 132/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 133/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9861\n",
            "Epoch 134/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 135/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 136/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 137/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9847\n",
            "Epoch 138/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 139/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 140/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 141/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9861\n",
            "Epoch 142/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 143/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 144/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 145/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 146/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 147/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 148/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 149/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0261 - accuracy: 0.9861\n",
            "Epoch 150/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 151/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 152/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 153/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 154/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 155/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 156/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9847\n",
            "Epoch 157/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 158/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 159/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 160/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 161/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9847\n",
            "Epoch 162/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9847\n",
            "Epoch 163/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 164/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9847\n",
            "Epoch 165/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 166/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9876\n",
            "Epoch 167/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 168/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 169/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 170/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 171/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 172/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 173/500\n",
            "43/43 [==============================] - 1s 16ms/step - loss: 0.0259 - accuracy: 0.9869\n",
            "Epoch 174/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 175/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 176/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 177/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 178/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 179/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 180/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9861\n",
            "Epoch 181/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 182/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 183/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 184/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 185/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 186/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 187/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9861\n",
            "Epoch 188/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 189/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9847\n",
            "Epoch 190/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9883\n",
            "Epoch 191/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 192/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 193/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 194/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 195/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9861\n",
            "Epoch 196/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9847\n",
            "Epoch 197/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9847\n",
            "Epoch 198/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 199/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 200/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 201/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 202/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 203/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 204/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9854\n",
            "Epoch 205/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9869\n",
            "Epoch 206/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 207/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 208/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9847\n",
            "Epoch 209/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9861\n",
            "Epoch 210/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 211/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 212/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 213/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 214/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9861\n",
            "Epoch 215/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9876\n",
            "Epoch 216/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9847\n",
            "Epoch 217/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 218/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 219/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 220/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 221/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 222/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9861\n",
            "Epoch 223/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 224/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 225/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9876\n",
            "Epoch 226/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 227/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 228/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 229/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 230/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 231/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9861\n",
            "Epoch 232/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 233/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9861\n",
            "Epoch 234/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9869\n",
            "Epoch 235/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9854\n",
            "Epoch 236/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 237/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 238/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9861\n",
            "Epoch 239/500\n",
            "43/43 [==============================] - 1s 13ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 240/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 241/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9869\n",
            "Epoch 242/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0263 - accuracy: 0.9854\n",
            "Epoch 243/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9840\n",
            "Epoch 244/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9869\n",
            "Epoch 245/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 246/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9840\n",
            "Epoch 247/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 248/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9876\n",
            "Epoch 249/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9876\n",
            "Epoch 250/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 251/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9869\n",
            "Epoch 252/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 253/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 254/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9854\n",
            "Epoch 255/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9847\n",
            "Epoch 256/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 257/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 258/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 259/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9869\n",
            "Epoch 260/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 261/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 262/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 263/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 264/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 265/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 266/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 267/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 268/500\n",
            "43/43 [==============================] - 1s 13ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 269/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9876\n",
            "Epoch 270/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9847\n",
            "Epoch 271/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 272/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 273/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 274/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 275/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9847\n",
            "Epoch 276/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 277/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0261 - accuracy: 0.9854\n",
            "Epoch 278/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 279/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 280/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9854\n",
            "Epoch 281/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 282/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9861\n",
            "Epoch 283/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9869\n",
            "Epoch 284/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 285/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 286/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 287/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9869\n",
            "Epoch 288/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9847\n",
            "Epoch 289/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 290/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 291/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9861\n",
            "Epoch 292/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.1053 - accuracy: 0.9533\n",
            "Epoch 293/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0939 - accuracy: 0.9708\n",
            "Epoch 294/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9840\n",
            "Epoch 295/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9861\n",
            "Epoch 296/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9861\n",
            "Epoch 297/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9869\n",
            "Epoch 298/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9854\n",
            "Epoch 299/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9861\n",
            "Epoch 300/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9854\n",
            "Epoch 301/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 302/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9876\n",
            "Epoch 303/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9869\n",
            "Epoch 304/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9854\n",
            "Epoch 305/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9854\n",
            "Epoch 306/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9847\n",
            "Epoch 307/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 308/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0261 - accuracy: 0.9876\n",
            "Epoch 309/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 310/500\n",
            "43/43 [==============================] - 1s 16ms/step - loss: 0.0261 - accuracy: 0.9840\n",
            "Epoch 311/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9854\n",
            "Epoch 312/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9876\n",
            "Epoch 313/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 314/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 315/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9861\n",
            "Epoch 316/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 317/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 318/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 319/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9869\n",
            "Epoch 320/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 321/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9861\n",
            "Epoch 322/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9861\n",
            "Epoch 323/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 324/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 325/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 326/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 327/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 328/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 329/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 330/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 331/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 332/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 333/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9847\n",
            "Epoch 334/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 335/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9840\n",
            "Epoch 336/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 337/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 338/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 339/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 340/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 341/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9869\n",
            "Epoch 342/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9847\n",
            "Epoch 343/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9869\n",
            "Epoch 344/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 345/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0252 - accuracy: 0.9861\n",
            "Epoch 346/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 347/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 348/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 349/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9869\n",
            "Epoch 350/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 351/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 352/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 353/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 354/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9876\n",
            "Epoch 355/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 356/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9861\n",
            "Epoch 357/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 358/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 359/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 360/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9847\n",
            "Epoch 361/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9861\n",
            "Epoch 362/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 363/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 364/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9869\n",
            "Epoch 365/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 366/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 367/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 368/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 369/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 370/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9861\n",
            "Epoch 371/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9847\n",
            "Epoch 372/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9861\n",
            "Epoch 373/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9876\n",
            "Epoch 374/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9861\n",
            "Epoch 375/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 376/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 377/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 378/500\n",
            "43/43 [==============================] - 1s 15ms/step - loss: 0.0254 - accuracy: 0.9869\n",
            "Epoch 379/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 380/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9869\n",
            "Epoch 381/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 382/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 383/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 384/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 385/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 386/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 387/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 388/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9854\n",
            "Epoch 389/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 390/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9861\n",
            "Epoch 391/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 392/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 393/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 394/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9876\n",
            "Epoch 395/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 396/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9869\n",
            "Epoch 397/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 398/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9869\n",
            "Epoch 399/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 400/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 401/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9847\n",
            "Epoch 402/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 403/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9847\n",
            "Epoch 404/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 405/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 406/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 407/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9883\n",
            "Epoch 408/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9840\n",
            "Epoch 409/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9861\n",
            "Epoch 410/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 411/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 412/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 413/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 414/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9869\n",
            "Epoch 415/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 416/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 417/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9861\n",
            "Epoch 418/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 419/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 420/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 421/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 422/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9854\n",
            "Epoch 423/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 424/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 425/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9847\n",
            "Epoch 426/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9876\n",
            "Epoch 427/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 428/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 429/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9876\n",
            "Epoch 430/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9847\n",
            "Epoch 431/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 432/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 433/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 434/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9876\n",
            "Epoch 435/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9847\n",
            "Epoch 436/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 437/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 438/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9869\n",
            "Epoch 439/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 440/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 441/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9847\n",
            "Epoch 442/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9876\n",
            "Epoch 443/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9847\n",
            "Epoch 444/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 445/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9854\n",
            "Epoch 446/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 447/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9847\n",
            "Epoch 448/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9854\n",
            "Epoch 449/500\n",
            "43/43 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 450/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9854\n",
            "Epoch 451/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 452/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 453/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9840\n",
            "Epoch 454/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 455/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9876\n",
            "Epoch 456/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9876\n",
            "Epoch 457/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 458/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9854\n",
            "Epoch 459/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9847\n",
            "Epoch 460/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9861\n",
            "Epoch 461/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9847\n",
            "Epoch 462/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9847\n",
            "Epoch 463/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 464/500\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9876\n",
            "Epoch 465/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9847\n",
            "Epoch 466/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 467/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9861\n",
            "Epoch 468/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9861\n",
            "Epoch 469/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9861\n",
            "Epoch 470/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 471/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9861\n",
            "Epoch 472/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9847\n",
            "Epoch 473/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9869\n",
            "Epoch 474/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9876\n",
            "Epoch 475/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9854\n",
            "Epoch 476/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9847\n",
            "Epoch 477/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9861\n",
            "Epoch 478/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9861\n",
            "Epoch 479/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9854\n",
            "Epoch 480/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9876\n",
            "Epoch 481/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9854\n",
            "Epoch 482/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9847\n",
            "Epoch 483/500\n",
            "43/43 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.9861\n",
            "Epoch 484/500\n",
            "43/43 [==============================] - 1s 12ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 485/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9861\n",
            "Epoch 486/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9869\n",
            "Epoch 487/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 488/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9854\n",
            "Epoch 489/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9854\n",
            "Epoch 490/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9861\n",
            "Epoch 491/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9861\n",
            "Epoch 492/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9861\n",
            "Epoch 493/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9861\n",
            "Epoch 494/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9861\n",
            "Epoch 495/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9847\n",
            "Epoch 496/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9854\n",
            "Epoch 497/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9869\n",
            "Epoch 498/500\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9876\n",
            "Epoch 499/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9876\n",
            "Epoch 500/500\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ac55c5a3ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('word_prediction2.h5')"
      ],
      "metadata": {
        "id": "HIKMUBwxB3gj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/tokenizer.pickle /content/drive/MyDrive/rnn"
      ],
      "metadata": {
        "id": "ChXmL_uCDIkK",
        "outputId": "b955fe9a-16a1-45fd-9428-e2df9d0adb75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/drive/MyDrive/rnn': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/tokenizer.pickle /content/drive/MyDrive/rnn"
      ],
      "metadata": {
        "id": "dzjnrgA-DOBj",
        "outputId": "06f81d74-d195-43b7-f61f-5f7d6a14dece",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/tokenizer.pickle': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "WzPGXc-4D6zu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/tokenizer.pickle','rb') as handle:\n",
        "  mytokenizer=pickle.load(handle)\n",
        "model=tf.keras.models.load_model('/content/word_prediction2.h5')"
      ],
      "metadata": {
        "id": "OrLC6AXQEUbt"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text= 'semiconductor'\n",
        "predict_next_words=15\n",
        "for i in range(predict_next_words):\n",
        "  token_list=mytokenizer.texts_to_sequences([input_text])[0]\n",
        "  token_list=pad_sequences([token_list],maxlen=model.input_shape[1],padding='pre')\n",
        "\n",
        "  predicted1=(model.predict(token_list))\n",
        "  predicted1_index=np.argmax(predicted1,axis=1)\n",
        "  output_word=mytokenizer.index_word[predicted1_index[0]]\n",
        "  input_text+=\" \"+output_word\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "7quI-NB_FTiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03534d9a-ecc4-4b8b-ace5-e8c0f455035d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "semiconductor key reason is that washington is keen to draw india closer so that it can\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlATS3CjF3Fj",
        "outputId": "103b1692-d70e-4fef-ce79-32f6c27c8ffe"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.51955466e-12, 3.97771930e-13, 1.47154433e-09, 1.78889394e-14,\n",
              "        1.23353966e-10, 4.13023532e-10, 6.74132982e-15, 2.16463024e-12,\n",
              "        8.56607198e-14, 1.39705261e-11, 4.84217026e-07, 1.97087979e-13,\n",
              "        4.65144069e-11, 3.26877969e-11, 2.28763321e-14, 5.32680176e-08,\n",
              "        1.37065387e-10, 3.81642368e-16, 2.75501998e-15, 3.38331902e-12,\n",
              "        9.37268510e-07, 1.77345950e-11, 3.02499237e-13, 2.29615593e-19,\n",
              "        7.99943905e-07, 7.19355131e-12, 3.32931213e-14, 3.75243050e-15,\n",
              "        1.53476798e-16, 1.13123167e-15, 3.77741848e-12, 6.72221474e-14,\n",
              "        2.87645907e-10, 1.23272538e-11, 2.46279857e-13, 8.23674489e-15,\n",
              "        4.18680322e-14, 8.93950780e-14, 5.21756978e-11, 1.14320931e-11,\n",
              "        1.03733599e-08, 3.88595846e-14, 1.32932128e-08, 1.67802594e-09,\n",
              "        5.98297995e-14, 1.53628975e-14, 4.24322816e-12, 1.16146426e-08,\n",
              "        5.82468082e-16, 1.72947675e-13, 7.21137594e-10, 1.22429075e-17,\n",
              "        2.98246289e-11, 3.33364878e-16, 3.27197880e-15, 7.18725508e-16,\n",
              "        2.52716711e-13, 1.56272998e-12, 1.10241270e-14, 4.32733446e-14,\n",
              "        1.86137581e-11, 1.90446595e-12, 1.78922530e-10, 2.01287258e-15,\n",
              "        1.36786122e-15, 6.74240164e-10, 1.42603897e-12, 5.61700166e-12,\n",
              "        8.79732731e-09, 1.91934260e-10, 8.60814919e-14, 5.77998347e-19,\n",
              "        3.62118401e-15, 1.34623551e-12, 3.63897020e-12, 1.69428301e-13,\n",
              "        3.42166454e-13, 1.49144100e-15, 2.43115505e-13, 8.88730669e-12,\n",
              "        8.66264576e-15, 1.24309538e-11, 2.06096221e-13, 3.70096870e-11,\n",
              "        4.26494696e-13, 2.06618129e-13, 7.11277148e-11, 3.85185044e-11,\n",
              "        1.35770721e-13, 1.84531643e-11, 3.19316323e-10, 9.25968848e-08,\n",
              "        2.81465563e-12, 2.31254016e-09, 5.32998938e-13, 1.78433240e-07,\n",
              "        4.41580800e-10, 4.94222881e-13, 1.12615174e-10, 1.80656684e-10,\n",
              "        4.09724338e-13, 7.77870563e-12, 2.07221995e-09, 9.00743770e-18,\n",
              "        1.26304112e-09, 1.78445800e-13, 5.67589886e-09, 9.86302151e-11,\n",
              "        3.48360501e-13, 2.71550109e-11, 6.84849677e-11, 2.13583478e-13,\n",
              "        2.91335712e-15, 9.99996901e-01, 2.10438695e-13, 9.46454137e-10,\n",
              "        4.44912743e-13, 6.59457298e-14, 1.58012847e-09, 8.68847268e-12,\n",
              "        5.39769509e-13, 6.25772258e-17, 1.56646091e-15, 8.10509158e-14,\n",
              "        2.76881789e-14, 7.37735285e-13, 1.76511916e-09, 1.41662859e-13,\n",
              "        5.35690069e-11, 3.52227436e-14, 4.17789277e-14, 7.02054248e-10,\n",
              "        5.32311859e-14, 1.36603619e-15, 5.36651496e-18, 3.07183071e-14,\n",
              "        1.88627380e-13, 3.11196265e-17, 4.70355886e-19, 4.19132402e-11,\n",
              "        3.67545553e-14, 1.49861067e-14, 2.41179630e-15, 1.93633685e-11,\n",
              "        3.26154465e-10, 2.09815848e-13, 8.50831883e-13, 7.81503567e-16,\n",
              "        5.16521721e-12, 1.87711005e-14, 3.35433941e-16, 2.79951756e-10,\n",
              "        3.17052352e-12, 1.46924237e-12, 6.85692388e-16, 1.34176541e-11,\n",
              "        2.71019007e-09, 9.12311871e-16, 4.44789503e-14, 5.41074509e-13,\n",
              "        8.10959402e-17, 7.72804987e-10, 5.10332705e-12, 1.94950241e-12,\n",
              "        1.95982579e-16, 1.96520759e-17, 6.50112234e-13, 1.04284847e-09,\n",
              "        1.86839087e-14, 3.06316611e-10, 5.92781249e-13, 2.38078092e-15,\n",
              "        3.88431141e-15, 6.79604073e-12, 2.00948563e-11, 7.84376755e-16,\n",
              "        2.47970219e-16, 7.84823036e-15, 9.55303663e-16, 1.20530912e-11,\n",
              "        1.74176697e-11, 7.70722353e-13, 5.01226187e-12, 2.93053277e-12,\n",
              "        2.71313362e-16, 4.93466487e-13, 6.90409576e-14, 9.96446155e-12,\n",
              "        3.67196074e-13, 1.55067608e-11, 3.57832344e-17, 5.22310543e-15,\n",
              "        3.49244961e-15, 4.71260672e-13, 1.27291190e-15, 1.37380787e-10,\n",
              "        8.80222707e-13, 9.50857164e-16, 3.07737679e-15, 1.15812611e-12,\n",
              "        6.06552501e-14, 5.33453475e-17, 1.43479602e-13, 7.90879406e-14,\n",
              "        4.68519598e-11, 1.31924216e-13, 3.78544485e-09, 6.09366333e-12,\n",
              "        7.07440012e-15, 2.58896463e-12, 1.44561674e-09, 1.18392871e-13,\n",
              "        4.80388256e-15, 1.03481975e-13, 5.07445580e-14, 1.21142002e-13,\n",
              "        9.37905818e-17, 5.34147579e-18, 8.79104567e-11, 2.12289089e-13,\n",
              "        1.52574316e-07, 2.16232891e-07, 7.77869218e-08, 9.18689902e-14,\n",
              "        4.73504439e-12, 4.58393826e-12, 4.14821416e-13, 5.36773515e-10,\n",
              "        4.56436928e-12, 2.86938445e-10, 4.81120742e-12, 4.05246236e-12,\n",
              "        1.29978476e-14, 2.30028475e-12, 1.67236669e-10, 2.36790703e-14,\n",
              "        3.18645833e-14, 8.92420835e-14, 8.98271156e-15, 1.82701315e-12,\n",
              "        4.24381464e-14, 1.31709761e-13, 1.49020698e-15, 3.35537002e-12,\n",
              "        1.81626124e-14, 4.51767703e-12, 1.21095386e-12, 1.56088767e-10,\n",
              "        4.86131101e-13, 8.08729060e-13, 3.42029088e-15, 1.73088091e-15,\n",
              "        1.76720487e-12, 2.66733623e-14, 3.68817554e-09, 6.73578435e-13,\n",
              "        2.32000590e-13, 9.19619524e-13, 4.96844381e-18, 1.38736106e-10,\n",
              "        2.61857619e-10, 1.03010027e-15, 5.39279111e-15, 8.80745875e-15,\n",
              "        1.11115953e-16, 3.46908752e-11, 7.19934355e-12, 2.31555761e-10,\n",
              "        2.17626799e-15, 3.12170076e-13, 3.62814374e-20, 1.48988369e-14,\n",
              "        7.64843392e-15, 2.68944892e-12, 7.16990080e-14, 8.17516801e-12,\n",
              "        5.33027658e-12, 2.45227666e-12, 2.59822524e-12, 9.00175388e-14,\n",
              "        5.56042061e-12, 6.80613547e-15, 4.84213689e-13, 3.05718119e-15,\n",
              "        2.15529969e-15, 7.22140230e-12, 3.45661379e-13, 1.95724470e-12,\n",
              "        1.26473676e-15, 7.97711619e-11, 3.09827630e-13, 5.22148412e-14,\n",
              "        5.34241596e-13, 1.11861787e-11, 9.86745191e-13, 2.63473421e-09,\n",
              "        2.18993402e-15, 1.40460128e-14, 4.40687822e-15, 1.69977331e-16,\n",
              "        4.57225716e-11, 1.77286910e-13, 2.75448259e-16, 4.35183920e-12,\n",
              "        3.11326964e-09, 1.84508069e-11, 4.38848402e-11, 1.26036727e-13,\n",
              "        1.51180463e-15, 2.77460954e-12, 6.87081143e-13, 7.29019384e-13,\n",
              "        2.79452780e-11, 6.55588014e-11, 1.38207141e-13, 1.68565596e-11,\n",
              "        4.05755778e-13, 3.33685174e-14, 1.58944212e-12, 3.56443289e-14,\n",
              "        1.44029721e-12, 2.33299990e-12, 3.79304318e-15, 4.48347549e-13,\n",
              "        5.32886365e-12, 2.97423718e-11, 3.08157227e-14, 1.51674939e-15,\n",
              "        1.10763966e-14, 5.17728179e-15, 3.50245625e-15, 6.35177501e-12,\n",
              "        9.06334353e-18, 5.33364206e-16, 1.51527460e-15, 9.12979094e-19,\n",
              "        1.47885745e-16, 1.66160532e-12, 2.01700595e-13, 5.17583771e-16,\n",
              "        1.46756174e-16, 1.58594121e-16, 1.24342377e-13, 8.81144929e-13,\n",
              "        4.69963868e-12, 9.85811520e-18, 8.22921731e-20, 5.95515526e-14,\n",
              "        2.71290108e-12, 4.10028612e-16, 1.19034673e-15, 9.35568897e-13,\n",
              "        1.65450783e-13, 2.28071041e-14, 2.98254785e-15, 2.62753652e-10,\n",
              "        5.76915555e-12, 7.43220454e-14, 1.25853982e-12, 9.04846334e-16,\n",
              "        1.02325112e-14, 7.26178926e-12, 3.31875086e-17, 2.78354212e-15,\n",
              "        1.25489863e-16, 6.63348499e-12, 3.45888790e-10, 6.44252243e-14,\n",
              "        1.08275498e-11, 2.69919124e-13, 9.89452305e-15, 1.15735575e-15,\n",
              "        4.85609547e-16, 5.40782976e-15, 2.12545557e-13, 4.83885901e-17,\n",
              "        2.12765114e-12, 3.31796006e-13, 3.76361404e-14, 1.16767984e-11,\n",
              "        1.73923140e-10, 4.51405203e-15, 4.87681839e-10, 1.46023652e-14,\n",
              "        3.03195571e-15, 1.72182502e-16, 5.33795057e-11, 3.58122857e-19,\n",
              "        9.76914879e-14, 1.53768641e-16, 1.57024207e-15, 1.99862973e-11,\n",
              "        2.16113127e-09, 6.83225754e-10, 5.18861169e-11, 2.05220687e-13,\n",
              "        3.27285139e-12, 1.66180264e-11, 3.40752218e-11, 1.95647209e-12,\n",
              "        8.98800598e-19, 2.58612549e-13, 1.75403216e-11, 1.26150731e-13,\n",
              "        4.58143384e-14, 3.05319405e-16, 4.84584421e-12, 5.29460260e-11,\n",
              "        8.51115289e-11, 2.58973030e-12, 4.60844585e-10, 6.58948943e-15,\n",
              "        1.53523155e-15, 2.67684180e-10, 1.17916733e-12, 1.81370308e-10,\n",
              "        4.19064262e-12, 2.57546234e-10, 1.57758745e-12, 8.29979974e-10,\n",
              "        5.19642001e-13, 3.53226529e-14, 1.11450579e-14, 7.16619264e-11,\n",
              "        1.04107559e-13, 8.42385135e-13, 2.82412270e-14, 3.94309455e-12,\n",
              "        4.36610180e-14, 1.17297006e-15, 1.18980834e-12, 9.13871270e-11,\n",
              "        5.77421831e-16, 7.49172805e-13, 9.18675943e-14, 1.36357299e-12,\n",
              "        2.22016086e-11, 1.94054061e-11, 5.49163753e-12, 1.90158725e-16,\n",
              "        4.82446964e-11, 7.25326849e-14, 6.85909871e-11, 2.22516880e-10,\n",
              "        1.43961801e-13, 3.01214213e-13, 2.29247722e-14, 1.24601670e-16,\n",
              "        1.51469982e-11, 5.17680788e-15, 8.63507703e-12, 2.31182158e-16,\n",
              "        2.08464840e-16, 8.42271404e-16, 6.68693277e-14, 5.34416620e-18,\n",
              "        3.46100779e-13, 5.37618940e-13, 1.04067113e-12, 9.47680198e-11,\n",
              "        3.12408926e-13, 3.63742955e-12, 1.87314465e-13, 1.55817240e-13,\n",
              "        2.11888104e-14, 5.44741116e-17, 1.71495518e-16, 4.43039789e-12,\n",
              "        8.57864910e-17, 3.20513635e-13, 2.86099947e-15, 1.43042140e-13,\n",
              "        8.90612128e-13, 7.08187571e-16, 1.89977364e-17, 1.21848138e-16,\n",
              "        9.09765596e-10, 4.18843816e-15, 2.08383750e-16, 9.38969988e-15,\n",
              "        3.82001933e-17, 1.92636942e-14, 3.73523972e-20, 9.72192653e-16,\n",
              "        3.41932916e-13, 5.94789582e-12, 8.97751383e-13, 6.31794950e-10,\n",
              "        1.48447185e-10, 3.57295526e-10, 2.57367488e-10, 9.46803772e-15,\n",
              "        8.02876643e-16, 2.56653101e-15, 6.49042348e-11, 4.60496767e-13,\n",
              "        4.35263587e-12, 4.13738452e-15, 1.78133810e-11, 7.13471776e-14,\n",
              "        4.32122949e-11, 3.34325639e-13, 1.32506372e-15, 3.09144516e-10,\n",
              "        2.64003636e-13, 1.42039256e-12, 2.76795438e-16, 2.07748108e-15,\n",
              "        2.83836302e-14, 1.09590573e-13, 3.37085313e-13, 1.14790149e-13,\n",
              "        6.02065593e-17, 8.82763497e-16, 1.51075699e-13, 3.51678553e-09,\n",
              "        3.49887475e-09, 2.42557038e-12, 5.09046727e-15, 2.96573016e-10,\n",
              "        6.27315527e-19, 1.14271882e-11, 2.09908507e-15, 1.26827351e-11,\n",
              "        3.09286627e-14, 1.54493627e-12, 1.47133163e-12, 6.52980437e-13,\n",
              "        2.45023444e-15, 1.34071855e-12, 4.09217837e-15, 2.28212902e-14,\n",
              "        1.62884400e-10, 2.80069631e-11, 1.20856641e-11, 1.35158829e-10,\n",
              "        1.11507198e-13, 8.05377053e-15, 2.36781449e-12, 1.30495606e-11,\n",
              "        8.71677383e-12, 2.61020212e-15, 1.43458346e-12, 7.16477642e-17,\n",
              "        8.00747785e-16, 3.54928543e-17, 6.17909654e-14, 1.69203037e-15,\n",
              "        5.74746088e-13, 2.93859235e-16, 1.24274068e-17, 4.05983098e-18,\n",
              "        3.52459748e-15, 5.55152209e-11, 3.18586439e-13, 1.29995546e-11,\n",
              "        2.78687683e-16, 3.68600761e-10, 4.64720840e-12, 1.48097549e-15,\n",
              "        9.53938034e-16, 6.73133356e-15, 3.48296369e-15, 8.31625480e-12,\n",
              "        7.66902774e-12, 1.52795094e-12, 4.17343298e-14, 3.33921107e-12,\n",
              "        1.07058852e-13, 2.42501658e-15, 2.80051308e-12, 7.03661186e-15,\n",
              "        4.22591090e-16, 1.66697561e-13, 3.33302281e-14, 3.25791977e-10,\n",
              "        3.24267197e-12, 8.79007170e-15, 5.27923322e-15, 1.14269479e-11,\n",
              "        2.46802882e-12, 1.05863116e-12, 5.53944691e-17, 6.18663402e-17,\n",
              "        1.64683587e-16, 2.05348146e-15, 1.66528100e-14, 5.33559898e-11,\n",
              "        1.74453042e-14, 1.81356205e-13, 2.21920399e-11, 3.55545302e-12,\n",
              "        2.97643746e-12, 3.39102932e-14, 5.30205047e-11, 3.72467411e-13,\n",
              "        1.00246053e-11, 7.49905624e-11, 8.71100674e-12]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text= 'india'\n",
        "predict_next_words=15\n",
        "for i in range(predict_next_words):\n",
        "  token_list=mytokenizer.texts_to_sequences([input_text])[0]\n",
        "  token_list=pad_sequences([token_list],maxlen=model.input_shape[1],padding='pre')\n",
        "\n",
        "  predicted2=(model.predict(token_list))\n",
        "  predicted2_index=np.argmax(predicted2,axis=1)\n",
        "  output_word=mytokenizer.index_word[predicted2_index[0]]\n",
        "  input_text+=\" \"+output_word\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "i7lYPCYsF5Sz",
        "outputId": "c59d42e1-0432-494f-8358-619fe07eb2ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "india and the us have had major trade differences in recent years over tariffs trade relations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted2"
      ],
      "metadata": {
        "id": "X_szxFRrRrBL",
        "outputId": "a9ec6174-ba8c-49fa-b3c3-ee2a6d0fa52e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.47755590e-13, 2.41301628e-08, 3.14529392e-12, 6.75735455e-13,\n",
              "        4.37696008e-14, 1.34836716e-11, 5.98820646e-12, 1.29340511e-10,\n",
              "        6.54252650e-12, 8.30034208e-10, 2.28612092e-14, 4.55685296e-17,\n",
              "        9.69033014e-12, 8.24955160e-10, 1.59948487e-12, 2.67261644e-08,\n",
              "        3.60276226e-16, 4.88106666e-09, 4.17160837e-12, 1.87736965e-13,\n",
              "        1.51661503e-10, 6.66312776e-14, 7.11040818e-13, 8.62575961e-13,\n",
              "        3.82001453e-09, 1.86400645e-14, 2.37634547e-11, 4.07841732e-16,\n",
              "        5.29966661e-11, 1.10523971e-12, 8.73645081e-16, 2.56152098e-14,\n",
              "        4.51117789e-12, 1.41081262e-06, 1.74530518e-12, 7.41023555e-15,\n",
              "        1.07725020e-13, 1.31609013e-07, 5.72925431e-12, 3.82741460e-14,\n",
              "        1.52881494e-08, 3.50736717e-10, 1.56415188e-14, 4.42028920e-08,\n",
              "        9.45281722e-14, 8.90250262e-14, 3.74272477e-15, 6.95502544e-10,\n",
              "        8.30893427e-12, 6.22466488e-14, 8.35254623e-17, 9.12055347e-15,\n",
              "        7.16646653e-08, 1.01343218e-12, 3.49209897e-11, 1.89549304e-13,\n",
              "        2.13724772e-15, 2.68298946e-12, 1.71223761e-15, 2.38041656e-13,\n",
              "        7.65919272e-12, 2.11854001e-09, 1.01068615e-14, 2.00643199e-13,\n",
              "        7.29395988e-11, 6.20398233e-10, 4.90053033e-11, 7.24908986e-08,\n",
              "        8.36219982e-11, 1.51191878e-10, 5.80314730e-09, 5.31431554e-14,\n",
              "        1.28695941e-15, 5.79089621e-09, 2.51094650e-14, 6.00637706e-10,\n",
              "        6.57476712e-11, 7.79318277e-10, 8.41469117e-08, 2.46854539e-14,\n",
              "        3.80898091e-11, 1.42231617e-11, 5.43791044e-15, 9.63096269e-08,\n",
              "        3.17550743e-11, 4.13069795e-12, 2.00473197e-11, 3.03296582e-10,\n",
              "        1.55896997e-13, 2.55851438e-13, 1.36934547e-10, 3.11254089e-09,\n",
              "        2.94200948e-12, 3.56370207e-13, 1.82164749e-13, 1.06725878e-11,\n",
              "        3.98359035e-09, 5.00184529e-12, 1.65408380e-08, 3.42092413e-12,\n",
              "        5.72818903e-10, 1.26960091e-14, 2.02530111e-11, 1.70081451e-13,\n",
              "        5.55221060e-12, 6.03577897e-13, 1.10811058e-08, 7.97919727e-13,\n",
              "        1.10755638e-09, 3.84861344e-11, 8.80910535e-12, 1.84975733e-11,\n",
              "        8.65812820e-14, 1.27330235e-13, 8.60266285e-12, 1.70733636e-11,\n",
              "        3.15750768e-12, 4.63833104e-11, 3.47609719e-11, 3.58126029e-10,\n",
              "        1.65841854e-11, 7.75905395e-10, 1.22413447e-14, 3.20625232e-12,\n",
              "        8.71977560e-11, 1.15997869e-13, 6.99014846e-10, 1.75027648e-15,\n",
              "        6.97395048e-15, 2.83906315e-10, 1.18212081e-11, 1.20540619e-07,\n",
              "        3.48839577e-12, 1.83573018e-11, 6.75815697e-12, 3.61725164e-11,\n",
              "        1.15119257e-14, 2.27625609e-11, 4.50804826e-15, 2.60610825e-12,\n",
              "        1.50408169e-13, 3.47890010e-16, 7.99952213e-14, 1.61615984e-10,\n",
              "        3.35418130e-12, 1.45102883e-13, 1.56873292e-09, 3.61918578e-10,\n",
              "        2.04207082e-10, 6.93198331e-17, 3.17930835e-14, 1.13026931e-13,\n",
              "        9.99993563e-01, 4.40340653e-09, 8.30908421e-14, 8.49064250e-08,\n",
              "        4.95206056e-14, 2.06754558e-10, 1.21883775e-12, 4.56864407e-10,\n",
              "        2.51090950e-13, 1.11117223e-17, 2.40314414e-13, 8.55045906e-13,\n",
              "        3.58066407e-15, 4.54924676e-09, 4.26615514e-12, 1.88570759e-08,\n",
              "        4.20598980e-07, 5.57861006e-12, 2.71586543e-07, 4.98632232e-07,\n",
              "        2.27683039e-10, 6.83346175e-13, 7.38258501e-15, 4.73208538e-12,\n",
              "        2.62469428e-07, 1.82713070e-14, 2.29090373e-15, 5.42297283e-12,\n",
              "        7.93277041e-11, 2.96869329e-09, 1.10728604e-09, 6.92437982e-11,\n",
              "        1.49399885e-11, 2.65576207e-11, 3.78702235e-12, 3.91211748e-13,\n",
              "        1.39911790e-10, 2.03649489e-12, 6.83268885e-14, 1.36288092e-10,\n",
              "        1.96238470e-09, 2.16324341e-13, 1.84893888e-11, 1.54380881e-12,\n",
              "        6.88992891e-11, 4.67924137e-11, 2.61136501e-10, 3.57977493e-12,\n",
              "        1.60429626e-13, 1.03135613e-13, 1.21643977e-14, 9.50469651e-12,\n",
              "        3.07474601e-10, 1.96405175e-12, 3.60547658e-09, 2.93108791e-08,\n",
              "        4.49006526e-10, 2.80275081e-10, 1.32884068e-11, 8.17755423e-13,\n",
              "        1.97434513e-10, 2.79188375e-13, 1.79494624e-12, 1.18294074e-13,\n",
              "        6.51777807e-12, 3.41475796e-19, 8.96276976e-13, 4.07697097e-12,\n",
              "        1.32507208e-11, 3.74411385e-13, 3.76844497e-13, 8.12015906e-12,\n",
              "        4.37459178e-13, 2.86177249e-10, 1.67368354e-12, 4.62382667e-11,\n",
              "        5.27093072e-13, 3.14734268e-14, 8.27858940e-13, 3.81173530e-11,\n",
              "        8.10509971e-13, 3.70404618e-09, 1.67071728e-12, 1.68018689e-11,\n",
              "        1.19555021e-09, 4.30724114e-08, 1.92921745e-09, 3.11225546e-13,\n",
              "        2.74537476e-11, 1.91226998e-13, 5.74292729e-13, 6.81715303e-16,\n",
              "        3.38452216e-15, 9.95940743e-13, 6.03875326e-12, 5.43042228e-13,\n",
              "        1.28668574e-13, 9.73010734e-13, 2.80203835e-15, 2.55040062e-14,\n",
              "        6.15292955e-11, 4.81449089e-14, 5.10835985e-10, 1.18438002e-11,\n",
              "        5.79608340e-11, 3.46724033e-13, 6.69653406e-14, 7.27080549e-11,\n",
              "        1.28512652e-12, 1.70832012e-11, 3.23861733e-13, 5.46899657e-13,\n",
              "        2.10213444e-12, 1.84336241e-10, 5.51238222e-10, 2.18690083e-11,\n",
              "        7.62750280e-11, 1.18729596e-10, 2.39104722e-16, 3.42665417e-14,\n",
              "        6.53886830e-13, 2.81271832e-13, 1.43281359e-10, 1.06415300e-07,\n",
              "        5.20936183e-10, 5.38575044e-12, 1.18335647e-12, 1.91187430e-11,\n",
              "        8.37407810e-10, 8.44313786e-10, 3.62164222e-11, 2.66676969e-09,\n",
              "        5.79822856e-11, 7.32515871e-12, 5.38200491e-11, 1.39295509e-12,\n",
              "        1.21700098e-11, 6.78517030e-14, 1.47821683e-14, 1.40946540e-13,\n",
              "        9.23387977e-10, 1.01126366e-12, 1.90880168e-12, 1.35940507e-13,\n",
              "        5.59944591e-10, 7.48239253e-13, 5.39495271e-12, 1.48653229e-10,\n",
              "        2.56184851e-10, 9.30696752e-12, 1.46688078e-11, 8.33762855e-14,\n",
              "        1.11147121e-13, 2.62456133e-11, 1.22601319e-14, 1.16916107e-13,\n",
              "        1.35381553e-10, 1.19743806e-08, 4.75428197e-10, 5.77304662e-11,\n",
              "        2.32540305e-13, 1.79267773e-16, 2.36052616e-14, 5.53282429e-15,\n",
              "        1.24904655e-12, 4.37287095e-14, 9.04812891e-11, 1.93384378e-10,\n",
              "        2.63242119e-12, 2.44710658e-11, 9.88704358e-14, 3.49986047e-11,\n",
              "        1.07574667e-14, 6.20054319e-09, 6.59767074e-10, 1.58709962e-10,\n",
              "        1.51723676e-14, 1.60238711e-14, 4.38694762e-14, 8.83219618e-14,\n",
              "        2.62166031e-14, 2.69122967e-13, 1.78347983e-12, 2.98505977e-11,\n",
              "        1.83906818e-13, 9.74697840e-12, 3.23146111e-12, 1.29748391e-11,\n",
              "        6.72071516e-15, 1.41490027e-14, 1.08610515e-13, 3.25828010e-11,\n",
              "        3.11774532e-13, 2.53751335e-14, 2.07802234e-10, 6.87033624e-11,\n",
              "        8.57043996e-14, 5.81141512e-15, 1.57035919e-12, 1.99994806e-13,\n",
              "        3.28977015e-12, 3.31848368e-11, 6.95199497e-12, 2.78138918e-11,\n",
              "        1.03348642e-10, 5.19491676e-13, 1.65738945e-09, 1.35844984e-15,\n",
              "        1.46699158e-16, 4.16495180e-13, 2.71390097e-16, 2.04590811e-09,\n",
              "        7.08541624e-13, 1.97002760e-13, 2.91107624e-11, 8.37316397e-11,\n",
              "        3.29645789e-13, 7.83608595e-12, 1.32883613e-14, 1.01556838e-12,\n",
              "        9.08485781e-15, 5.22892710e-12, 5.24728047e-12, 1.13663401e-09,\n",
              "        2.11496367e-08, 7.88263118e-12, 2.38930403e-10, 1.72874735e-11,\n",
              "        8.55560241e-12, 1.81555304e-09, 6.02813968e-13, 6.95621616e-11,\n",
              "        1.80095619e-10, 1.36670830e-09, 5.73779774e-11, 8.73928100e-13,\n",
              "        7.57794850e-16, 3.66106695e-13, 1.58398013e-12, 2.96950159e-10,\n",
              "        5.45908319e-10, 3.96702116e-10, 4.13879738e-12, 4.25484138e-13,\n",
              "        5.75423659e-15, 3.70689943e-14, 4.33558849e-11, 1.88784399e-13,\n",
              "        4.12847644e-16, 3.29419956e-14, 6.39911098e-14, 1.02809289e-11,\n",
              "        8.12367155e-13, 8.39776162e-15, 3.47848730e-13, 5.65770451e-11,\n",
              "        2.52318444e-10, 2.65779537e-10, 3.29373790e-12, 1.15264818e-12,\n",
              "        2.80311934e-14, 4.33675855e-13, 1.51546362e-11, 5.17859852e-11,\n",
              "        5.80297511e-11, 7.21552321e-13, 7.56365370e-12, 3.35319947e-14,\n",
              "        2.19849177e-13, 3.19503470e-14, 1.81375666e-13, 7.87396813e-14,\n",
              "        1.82610541e-15, 2.54817889e-10, 4.51345716e-09, 1.46520502e-08,\n",
              "        1.63150092e-13, 7.62589536e-13, 1.03381814e-09, 2.76774090e-11,\n",
              "        1.04503179e-12, 7.81200733e-14, 3.13183021e-16, 1.95747715e-12,\n",
              "        1.10807887e-08, 2.48755313e-12, 2.65907928e-13, 1.42914277e-17,\n",
              "        1.67029188e-14, 1.72300461e-13, 7.26193151e-12, 3.39736720e-15,\n",
              "        8.16219003e-09, 2.82897637e-14, 8.16126333e-11, 1.60377523e-14,\n",
              "        3.26378139e-13, 5.99085989e-11, 2.24388425e-10, 4.03517194e-12,\n",
              "        5.23801814e-13, 2.23152261e-11, 4.04491635e-10, 8.99251767e-12,\n",
              "        1.28482338e-11, 2.10625319e-11, 5.44792926e-11, 9.85197926e-13,\n",
              "        2.46937332e-11, 1.65807798e-10, 2.34825912e-13, 4.37797009e-14,\n",
              "        2.75265887e-14, 2.18293130e-13, 4.66644258e-11, 1.41253290e-14,\n",
              "        4.93677581e-13, 1.63404137e-10, 1.63795211e-09, 2.65152440e-12,\n",
              "        2.73381361e-13, 1.24968037e-12, 2.80348305e-14, 2.55449763e-12,\n",
              "        2.49453155e-13, 8.58929152e-14, 1.18541223e-12, 3.95680362e-14,\n",
              "        2.29262274e-14, 6.29566440e-13, 3.03430173e-14, 8.47803832e-15,\n",
              "        3.89396062e-13, 7.34601269e-10, 1.18949111e-12, 3.72156733e-12,\n",
              "        2.27759570e-13, 6.44346868e-11, 1.85449902e-14, 1.74266081e-12,\n",
              "        3.83997616e-07, 6.18193837e-07, 6.18124840e-09, 5.21175480e-07,\n",
              "        3.32098997e-12, 4.50399495e-10, 7.69196540e-10, 1.75634129e-09,\n",
              "        2.48721790e-07, 2.77603246e-10, 3.70040573e-15, 4.15736429e-13,\n",
              "        2.12622628e-10, 1.98498764e-08, 8.47118287e-08, 7.31897529e-11,\n",
              "        1.75365999e-09, 2.43555176e-09, 2.66948312e-12, 9.43494415e-15,\n",
              "        3.00951179e-14, 1.21026253e-11, 5.22896226e-10, 3.27337604e-13,\n",
              "        3.78692972e-15, 1.23359369e-15, 1.07210112e-13, 3.26043706e-11,\n",
              "        4.54680645e-14, 6.66742527e-14, 1.83235859e-14, 7.87387869e-14,\n",
              "        4.74090006e-13, 1.48531090e-14, 1.69832393e-14, 4.57781091e-14,\n",
              "        1.21945038e-14, 4.15064906e-15, 1.11518515e-13, 2.41569247e-11,\n",
              "        1.61495883e-09, 8.25557955e-10, 2.29810203e-12, 1.26218480e-12,\n",
              "        2.73005919e-15, 2.77953269e-15, 5.39960475e-16, 3.75257903e-13,\n",
              "        2.70762823e-13, 9.82424992e-12, 2.96048686e-10, 2.09871471e-14,\n",
              "        1.93460883e-16, 7.64355848e-17, 7.19826386e-15, 5.61033099e-13,\n",
              "        1.17171897e-14, 2.54863942e-11, 3.60653161e-15, 1.67409532e-12,\n",
              "        9.84222287e-11, 4.35440295e-10, 5.66512288e-11, 1.22252174e-11,\n",
              "        3.23965993e-10, 1.36873779e-09, 9.82412018e-08, 2.02473927e-09,\n",
              "        8.66124741e-11, 1.21763417e-12, 2.07370755e-13, 7.42059972e-12,\n",
              "        1.29491322e-14, 8.93184615e-13, 3.92437920e-14, 5.09446907e-16,\n",
              "        9.53260975e-14, 2.24607988e-11, 1.91681350e-12, 1.55985502e-11,\n",
              "        2.83786133e-10, 6.87568763e-14, 7.12295112e-09, 2.91324811e-11,\n",
              "        4.80132144e-07, 1.85476889e-09, 1.82938198e-08, 2.65697308e-11,\n",
              "        2.65196800e-13, 2.17028557e-13, 6.93133647e-13, 2.39388266e-11,\n",
              "        2.58574325e-12, 2.17153948e-10, 1.37264748e-11, 4.38499253e-13,\n",
              "        2.17474799e-17, 1.37367277e-13, 2.48182453e-15, 3.29411791e-14,\n",
              "        1.72808371e-12, 1.61325484e-11, 1.38069742e-12, 9.01060615e-10,\n",
              "        3.42217682e-12, 3.00286409e-08, 1.94852207e-12]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_Vpev-gRts-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}